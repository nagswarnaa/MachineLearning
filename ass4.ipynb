{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagswarnaa/MachineLearning/blob/main/ass4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MhQ9m82O9IMb"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(object):\n",
        "        object.ip = None\n",
        "        object.op = None\n",
        "\n",
        "    def forward(object, data_ip):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(object, error_op, alpha):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7oVuAsVD9IMd"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "class LinearLayer(Layer):\n",
        "    # len_ip = number of ip neurons\n",
        "    # len_op = number of op neurons\n",
        "    def __init__(object, len_ip, len_op):\n",
        "        object.wghts = np.random.rand(len_ip, len_op) - 0.5\n",
        "        object.bs = np.random.rand(1, len_op) - 0.5\n",
        "\n",
        "    # returns op for a given ip\n",
        "    def forward(object, ip_data):\n",
        "        object.ip = ip_data\n",
        "        object.op = np.dot(object.ip, object.wghts) + object.bs\n",
        "        return object.op\n",
        "\n",
        "    # computes dE/dW, dE/dB for a given op_error=dE/dY. Returns ip_error=dE/dX.\n",
        "    def backward(object, op_error, learning_rate):\n",
        "        ip_error = np.dot(op_error, object.wghts.T)\n",
        "        wghts_error = np.dot(object.ip.T, op_error)\n",
        "        # dbs = op_error\n",
        "\n",
        "        # update parameters\n",
        "        object.wghts =object.wghts- (learning_rate * wghts_error)\n",
        "        object.bs =object.bs- (learning_rate * op_error)\n",
        "        return ip_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kwNDIGbb9IMe"
      },
      "outputs": [],
      "source": [
        "class TangentActivation(Layer):\n",
        "    \n",
        "    def forward(object, ip_data):\n",
        "        object.ip = ip_data\n",
        "        object.op = np.tanh(object.ip)\n",
        "        return object.op\n",
        "\n",
        "    def backward(object, op_error, learning_rate):\n",
        "        return (1-np.tanh(object.ip)**2 )* op_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CM-pFZbP9IMe"
      },
      "outputs": [],
      "source": [
        "class SigmoidActivation(Layer):\n",
        "    \n",
        "    def forward(object, ip_data):\n",
        "        object.ip = ip_data\n",
        "        object.op =  (1/(1 + np.exp(-object.ip)))\n",
        "        return object.op\n",
        "\n",
        "    def backward(object, op_error, learning_rate):\n",
        "        return ( np.exp(-object.ip)/(1+np.exp(-object.ip)**2))* op_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xQI-SDMW9IMe"
      },
      "outputs": [],
      "source": [
        "class SoftMaxActivation(Layer):\n",
        "    \n",
        "    def forward(object, ip_data):\n",
        "        object.ip = ip_data\n",
        "        object.op =  (np.exp(ip_data - np.max(ip_data)) / np.exp(ip_data - np.max(ip_data)).sum())\n",
        "        return object.op\n",
        "\n",
        "    def backward(object, op_error, learning_rate):\n",
        "        return ( np.exp(-object.ip)/(1+np.exp(-object.ip)**2))* op_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0O1VxmGH9IMf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cross_entropy_loss(pred,target):\n",
        "    return -target * np.log(pred)\n",
        "\n",
        "def cross_entropy_loss_grad(pred,target):\n",
        "        return target - pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5vk5AKEp9IMf"
      },
      "outputs": [],
      "source": [
        "class Sequential:\n",
        "    def __init__(object):\n",
        "        object.layers = []\n",
        "\n",
        "    def appendLayer(object, layer):\n",
        "        object.layers.append(layer)\n",
        "\n",
        "    #Predicting Using Forward Propagation\n",
        "    def predict(object, ip_data):\n",
        "        result = []\n",
        "        for i in range(len(ip_data)):\n",
        "            op = ip_data[i]\n",
        "            for layer in object.layers:\n",
        "                op = layer.forward(op)\n",
        "            result.append(op)\n",
        "\n",
        "        return result\n",
        "\n",
        "    #Training Neural Network\n",
        "    def fit(object, x_train, y_train, epochs, learning_rate):\n",
        "        for i in range(epochs):\n",
        "            err = 0\n",
        "            for j in range(len(x_train)):\n",
        "                # forward propagation\n",
        "                op = x_train[j]\n",
        "                for layer in object.layers:\n",
        "                    op = layer.forward(op)\n",
        "\n",
        "                # backward propagation\n",
        "                error = cross_entropy_loss_grad(y_train[j], op)\n",
        "                for layer in reversed(object.layers):\n",
        "                    error = layer.backward(error, learning_rate)\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX0ecdF_9IMg",
        "outputId": "45f9021f-ea5a-4cbf-fd3c-bb16a66ee05f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[0.50029431]]), array([[0.50131251]]), array([[0.49896495]]), array([[0.50006749]])]\n",
            "[array([[0.49557089]]), array([[0.49980345]]), array([[0.50177823]]), array([[0.50577121]])]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Training Data \n",
        "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
        "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
        "\n",
        "# Using Sigmoid function\n",
        "\n",
        "#Building Network\n",
        "nnworkSigm = Sequential()\n",
        "nnworkSigm.appendLayer(LinearLayer(2, 2))\n",
        "nnworkSigm.appendLayer(SigmoidActivation())\n",
        "nnworkSigm.appendLayer(LinearLayer(2, 1))\n",
        "nnworkSigm.appendLayer(SigmoidActivation())\n",
        "\n",
        "#Fitting Network\n",
        "nnworkSigm.fit(x_train, y_train, epochs=1000, learning_rate=0.1)\n",
        "out = nnworkSigm.predict(x_train)\n",
        "print(out)\n",
        "\n",
        "\n",
        "# Using Tan function\n",
        "\n",
        "#Building Network\n",
        "nnworkTan = Sequential()\n",
        "nnworkTan.appendLayer(LinearLayer(2, 3))\n",
        "nnworkTan.appendLayer(SigmoidActivation())\n",
        "nnworkTan.appendLayer(LinearLayer(3, 1))\n",
        "nnworkTan.appendLayer(SigmoidActivation())\n",
        "\n",
        "#Fitting Network\n",
        "nnworkTan.fit(x_train, y_train, epochs=1000, learning_rate=0.1)\n",
        "out = nnworkTan.predict(x_train)\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1iLszBE9IMi",
        "outputId": "808e8e8f-3b66-46df-9824-421b745589b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            "   0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            "   0.96862745 0.49803922 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            "   0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "   0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.19215687\n",
            "   0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            "   0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            "   0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            "   0.96862745 0.94509804 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            "   0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.04313726\n",
            "   0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.13725491 0.94509804\n",
            "   0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            "   0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            "   0.5882353  0.10588235 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            "   0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.15294118 0.5803922\n",
            "   0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            "   0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.07058824 0.67058825\n",
            "   0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            "   0.3137255  0.03529412 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.53333336 0.99215686\n",
            "   0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28*28)\n",
        "X_train = X_train.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "\n",
        "print(X_train[0 : 1, : ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = []\n",
        "for i in range(len(y_train)):\n",
        "  temp.append(to_categorical(y_train[i], num_classes=10))\n",
        "\n",
        "y_train = np.array(temp)\n",
        "\n",
        "temp = []\n",
        "for i in range(len(y_test)):\n",
        "  temp.append(to_categorical(y_test[i], num_classes=10))  \n",
        "   \n",
        "y_test = np.array(temp)"
      ],
      "metadata": {
        "id": "F2CHuEvD-T5v"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "accdffe619291f08a2ff010477572ccf3e2886b15af7e05a7a2b450f2b84ea24"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}